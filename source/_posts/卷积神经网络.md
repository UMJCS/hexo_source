---
title: 卷积神经网络
date: 2017-07-03 00:22:01
tags: 标签
categories: Machine learning
---

## sigmoid function
g(z)=1/(1+e^(-z))
z=w1*x1+w2*x2+b (weight,event,bias)

!["sigmoid"](/img/cnn1.jpg)

1. sigmoid函数的功能是相当于把一个实数压缩至0到1之间。当z是非常大的正数时，g(z)会趋近于1，而z是非常大的负数时，则g(z)会趋近于0。
2. 换言之，只有x1和x2都取1的时候，g(z)→1，判定为正样本；x1或x2取0的时候，g(z)→0，判定为负样本，如此达到分类的目的

## 层级结构

!["层级结构"](/img/cnn2.jpg)

最左边是数据输入层，对数据做一些处理，比如去均值（把输入数据各个维度都中心化为0，避免数据过多偏差，影响训练效果）、归一化（把所有的数据都归一到同样的范围）、PCA/白化等等。CNN只对训练集做“去均值”这一步。

1. CONV：卷积计算层，线性乘积 求和。
2. RELU：激励层，上文2.2节中有提到：ReLU是激活函数的一种。
3. POOL：池化层，简言之，即取区域平均或最大。